{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mudaser Ali ANN Classifier Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTtWhRuoUqGQ",
        "colab_type": "text"
      },
      "source": [
        "# **The following code may be used to build an Artificial Neural Network (ANN) for the purpose of classification. This may be used as the foundation of other models, such as a geosegmentation model.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M235NLhGW6v2",
        "colab_type": "text"
      },
      "source": [
        "Sample datasets to test this model may be found in the UCI machine learning repository:\n",
        "https://archive.ics.uci.edu/ml/index.php"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNT8XY9YU_OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 1 - Import essential libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvGVbWTdWN8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 2 - Import the dataset.\n",
        "  #The format of the dataset will affect the pandas function used to read it. \n",
        "  #Store all explanatory variables in the variable x.\n",
        "  #Store the dependent variable in the variable y.\n",
        "data = pd.read_csv('file_name.csv')\n",
        "x = data.iloc[:,:].values\n",
        "y = dataset.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xcVPT_HXUBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 3 - Encode any categorical data.\n",
        "  #Where any categorical data has more than two categories, the OneHotEncoder must be used. \n",
        "  #This is used to prevent the model from establishing hierarchies between the models. \n",
        "  #If the categorical variable is binary, the Label encoder may be used.\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "column_tr = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [1])], remainder = 'passthrough')\n",
        "variable_name = np.array(column_tr.fit_transform(variable_name))\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_enc = LabelEncoder()\n",
        "variable_name[:, column_number] = label_enc.fit_transform(variable_name[:,column_number])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wufLIvkyY0es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 4 - Split the dataset into the Training set and Test set\n",
        "  #Splitting the dataset should help to prevent overfitting.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw3VYlX-Z67D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 5 - Apply feature scaling to the explanatory variable training and test set.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVFC03eEat26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 6 - Create the Ann as an object of the sequential class, so that it can be built in layers.\n",
        "ANN = tf.keras.models.Sequential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaEBizhybST6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 7 - Add the input layer and first hidden layer of neurons to the ANN.\n",
        "  #If an ANN only contains one hidden layer of neurons between the input and output layer, it is referred to as a shallow learning model.\n",
        "  #The 'units' hyperparameter specifies the number of neurons in the hidden layer.\n",
        "  #The rectified linear activation function is chosen for this model. \n",
        "ANN.add(tf.keras.layers.Dense(units = 10, activation = 'relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMz_6JR6cDC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 8 - Add the second hidden layer of neurons to the ANN.\n",
        "  #If an ANN has more than one hidden layer of neurons between the input and output layer, it is referred to as a deep learning model.\n",
        "ANN.add(tf.keras.layers.Dense(units = 10, activation = 'relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISUR1rt7crl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 9 - Add the output layer to the ANN.\n",
        "  #The ANN here is being built for a binary classifier model, so the units hyperparameter is set to 1.\n",
        "  #If the dependent variable takes more than 2 classes, this must be reflected in the 'units' hyperparameter, with 1 neuron for each potential class. \n",
        "  #The sigmoid activation function is used to get probabilities associated with the outcome of the dependent variable being 1.\n",
        "ANN.add(tf.keras.layers.Dense(units=1, activation ='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzz3A_QVqhpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 10 - Compile the ANN\n",
        "  #The 'adam' optimiser is used to perform stochastic gradient descent to obtain the minimum cost function value.\n",
        "  #The loss function is set to 'binary_crossentropy', as it is assumed that the dependent variable output is binary. \n",
        "  #If the dependent variable takes more than 2 classes, the loss function must be set to 'binary_crossentropy'.\n",
        "    'accuracy' is chosen as the metric with which to evaluate the ANN.\n",
        "ANN.compile(optimiser = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v4suEymrnqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 11 - Train the ANN on using the training data.\n",
        "  #The 'batch_size' hyperparameter refers to the number of samples the algorithm processes from the training data before updating the weights of the model. \n",
        "    #This is set to 32 as a default value.\n",
        "  #The 'epochs' hyperparameter dictates the number of compltete passes the algorithm makes through the training dataset. \n",
        "ANN.fit(x_train, y_train, batch_size = 32 , epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee5CsOUNvSVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 12 - Predict the Test set results\n",
        "  #y_prediction is specified as being greater than 0.5 to obtain the final binary output, instead of the probability the output is 1.\n",
        "y_prediction = ANN.predict(x_test)\n",
        "y_prediction = (y_prediction > 0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8kHO-ajwXBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 13 - Generate a confusion matrix to assess the accuracy of the model\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "matrix = confusion_matrix(y_test, y_prediction)\n",
        "print(matrix)\n",
        "\n",
        "accuracy_score(y_test, y_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wUMprgJyrO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use the model to make predictions\n",
        "  #The model may be used to make predictions. \n",
        "  #Populate the following with values corresponding to the independent variables, in the order the variables' colu appear in the dataset.\n",
        "\n",
        "general_prediction = ANN.predict(scaler.transform([[independent_variable_values]]))\n",
        "\n",
        "print(general_prediction)\n",
        "\n",
        "print(general_prediction> 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}